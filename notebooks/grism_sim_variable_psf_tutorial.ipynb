{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ded6a76",
   "metadata": {},
   "source": [
    "Created June 6, 2025. \\\n",
    "Last revised June 6, 2025."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef001cd1",
   "metadata": {},
   "source": [
    "# Grism sim w/variable, wavelength-dependent PSF\n",
    "\n",
    "This notebook is intended as a tutorial for the current state of Roman Grism Simulations using wavelength-dependent PSFs. All functions will be defined locally with comments pointing to files containing these functions, with the exception of roman_coords_transform, which is imported from observing-program/py for brevity (it's like 1000 lines long)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d235ae5",
   "metadata": {},
   "source": [
    "## Imports and function definitions\n",
    "This section includes import cells and cells with function definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dcfa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import h5py\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "from astropy.wcs import WCS\n",
    "from astropy import units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "import os, sys\n",
    "import pysynphot as S\n",
    "\n",
    "from grizli.model import GrismFLT\n",
    "import grizli.fake_image # linting software highlighting this as unused is mistaken; see cell 10 lines 14 & 15; DO NOT REMOVE\n",
    "\n",
    "import image_utils as iu\n",
    "import psf_grid_utils as pgu\n",
    "\n",
    "import yaml\n",
    "import json\n",
    "import hashlib\n",
    "\n",
    "try:\n",
    "    import stpsf\n",
    "except:\n",
    "    import webbpsf as stpsf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29037145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell reads in environment variables.\n",
    "\n",
    "github_dir=os.getenv('github_dir')\n",
    "if github_dir is None:\n",
    "    print('github_dir environment variable has not been set, will cause problems if not explicitly set in function calls')\n",
    "\n",
    "psf_grid_data_read=os.getenv('psf_grid_data_read')\n",
    "if psf_grid_data_read is None:\n",
    "    print('psf_grid_data_read environment variable has not been set')\n",
    "\n",
    "sys.path.append(github_dir+'/observing-program/py')\n",
    "import roman_coords_transform as ctrans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbff9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell mimics/copies from grism_sim/py/image_utils.py\n",
    "\n",
    "wfi = stpsf.roman.WFI()\n",
    "wfi.filter = \"GRISM0\" #eventually make this detector specific\n",
    "\n",
    "def star_postage_grid(psf_grid, mag, detx=2044, dety=2044, fov_pixels=364):\n",
    "    flux = mag2flux(mag)\n",
    "\n",
    "    x_0 = int(detx)\n",
    "    y_0 = int(dety)\n",
    "    y, x = np.mgrid[y_0-fov_pixels:y_0+fov_pixels, x_0-fov_pixels:x_0+fov_pixels]\n",
    "\n",
    "    psf = psf_grid.evaluate(x=x, y=y, x_0=detx, y_0=dety, flux=flux).astype(np.float32)\n",
    "    return psf\n",
    "\n",
    "def gal_postage_grid(psf_grid, detx=2044, dety=2044, fov_pixels=364, flux=1):\n",
    "\n",
    "    x_0 = int(detx)\n",
    "    y_0 = int(dety)\n",
    "    y, x = np.mgrid[y_0-fov_pixels:y_0+fov_pixels, x_0-fov_pixels:x_0+fov_pixels]\n",
    "\n",
    "    psf = psf_grid.evaluate(x=x, y=y, x_0=detx, y_0=dety, flux=flux)\n",
    "    return psf\n",
    "\n",
    "#fiducial zero point set based on 2022 sim below\n",
    "def mag2flux(mag,zp=26.5):\n",
    "    f0 = 10**(0.4*zp)\n",
    "    flux = f0*10**(-0.4*mag) #mag = 26.5 - 2.5*np.log10(sumflux)\n",
    "    return flux\n",
    "\n",
    "def fake_header_wcs(crval1, crval2, crpix2=2044,crpix1=2044, cdelt1=0.11, cdelt2=0.11,\n",
    "                crota2=0.0,naxis1=4088,naxis2=4088):\n",
    "    #make empty hdu header and add wcs \n",
    "    \n",
    "    hdu = fits.PrimaryHDU()\n",
    "    \n",
    "    return add_wcs(hdu,crval1, crval2, crpix2,crpix1, cdelt1, cdelt2, crota2,naxis1,naxis2)\n",
    "\n",
    "\n",
    "def add_wcs(hdu,crval1, crval2, crpix2=2044,crpix1=2044, cdelt1=0.11, cdelt2=0.11,\n",
    "                crota2=0.0,naxis1=4088,naxis2=4088):\n",
    "\n",
    "    #add wcs to existing header\n",
    "    #maintain consistency with https://github.com/roman-grs-pit/observing-program/blob/main/py/footprintutils.py, at some point make both use same function\n",
    "    # crota2 - degree\n",
    "    # cdelt1 - arcsec\n",
    "    # cdelt2 - arcsec\n",
    "\n",
    "    #hdu = fits.PrimaryHDU()\n",
    "    #hdu.header\n",
    "\n",
    "    # http://stsdas.stsci.edu/documents/SUG/UG_21.html\n",
    "\n",
    "    theta = crota2*np.pi/180. # radians\n",
    "    cdelt1 /= 3600. # deg\n",
    "    cdelt2 /= 3600. # deg\n",
    "\n",
    "    R = np.array([\n",
    "        [-1*np.cos(theta), 1*np.sin(theta)],\n",
    "        [1*np.sin(theta), np.cos(theta)],\n",
    "    ])\n",
    "\n",
    "\n",
    "    cd1_1 = cdelt1*R[0,0]\n",
    "    cd1_2 = cdelt2*R[0,1]\n",
    "    cd2_1 = cdelt1*R[1,0]\n",
    "    cd2_2 = cdelt2*R[1,1]\n",
    "                    \n",
    "    hdu.header.set('NAXIS',2) # pixels\n",
    "    hdu.header.set('NAXIS1',naxis1) # pixels\n",
    "    hdu.header.set('NAXIS2',naxis2) # pixels\n",
    "\n",
    "    hdu.header.set('WCSAXES',2) # pixels\n",
    "    hdu.header.set('CTYPE1','RA---TAN')\n",
    "    hdu.header.set('CTYPE2','DEC--TAN')\n",
    "    hdu.header.set('CRVAL1',crval1) # deg\n",
    "    hdu.header.set('CRVAL2',crval2) # deg\n",
    "    hdu.header.set('CRPIX1',crpix1) # pixels\n",
    "    hdu.header.set('CRPIX2',crpix2) # pixels\n",
    "    #hdu.header.set('CDELT1',cdelt1)\n",
    "    #hdu.header.set('CDELT2',cdelt2)\n",
    "    #hdu.header.set('CROTA2',crota2)\n",
    "    hdu.header.set(\"CD1_1\",cd1_1)\n",
    "    hdu.header.set(\"CD1_2\",cd1_2)\n",
    "    hdu.header.set(\"CD2_1\",cd2_1)\n",
    "    hdu.header.set(\"CD2_2\",cd2_2)\n",
    "\n",
    "    return hdu.header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b44a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell mimics/copies from psf_grids/py/psf_grid_utils.py\n",
    "\n",
    "def load_psf_grid(grid_file, psf_grid_data_read=psf_grid_data_read):\n",
    "    \"\"\"\n",
    "    Reads in a saved GriddedPSFModel fits file. Returns that file.\n",
    "    \"\"\"\n",
    "    filepath = os.path.join(psf_grid_data_read, grid_file)\n",
    "    grid = stpsf.utils.to_griddedpsfmodel(filepath)\n",
    "    return grid\n",
    "\n",
    "def dict_hash(dict):\n",
    "    \"\"\"\n",
    "    Return a SHA256 hash of a dictionary, order-independent.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert dictionary to a JSON string with sorted keys\n",
    "    dict_json = json.dumps(dict, sort_keys=True, separators=(',', ':'))\n",
    "    # Encode and hash\n",
    "    version_hash = hashlib.sha256(dict_json.encode('utf-8')).hexdigest()\n",
    "\n",
    "    return version_hash\n",
    "\n",
    "def check_version(filepath, ext=0, **kwargs):\n",
    "    \"\"\"\n",
    "    Opens the fits located at {filepath}. Computes expected version_hash value from\n",
    "    kwargs. Checks value against header. If values are equal, returns a 0. Else,\n",
    "    prints header and returns a 1.\n",
    "    \"\"\"\n",
    "    \n",
    "    kwargs[\"stpsfver\"] = stpsf.__version__\n",
    "    expected_hash = dict_hash(kwargs)\n",
    "\n",
    "    file = fits.open(filepath)\n",
    "    header = file[ext].header\n",
    "\n",
    "    if header[\"verhash\"] == expected_hash:\n",
    "        print(f\"\\nVersion hash matches expected value\")\n",
    "        return 0\n",
    "    else:\n",
    "        print(header.tostring(sep='\\n'))\n",
    "        print(f\"\\nVersion hash does not match\")\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f15ae1",
   "metadata": {},
   "source": [
    "## Define the simulation parameters\n",
    "\n",
    "With imports complete, environment variable read in, and helper functions defined, now we begin definind the sim. We start by created two catalogs with objects to simulate, one with stars, the other with galaxies. The, we define the telescope pointing, which detector to simulate, and where to save the output fits files.\n",
    "\n",
    "This mimics the files in grism_sim/scripts which define these things and pass them into mk_grism and mk_ref_and_grism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b493265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the purposes of this tutorial, we define the star catalog here in the notebook.\n",
    "\n",
    "ind =   [0,       1]            # index\n",
    "tmp =   [154.0,   154.0]        # star_template_index\n",
    "mag =   [1.0,     1.0]          # magnitude\n",
    "RA =    [9.4,     9.45]        # RA\n",
    "DEC =   [1.05,   1.025]          # DEC\n",
    "\n",
    "star_input = Table([ind, tmp, mag, RA, DEC],\n",
    "               names=(\"index\", \"star_template_index\", \"magnitude\", \"RA\", \"DEC\"))\n",
    "\n",
    "# star_input = Table.read('/global/cfs/cdirs/m4943/grismsim/stars/sim_star_cat_galacticus.ecsv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc934d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run galaxies, you must have the right galaxy mocks in the mockdir. We will not assume that you have those and will set gal_input=None by default. \n",
    "# If you would like to simulate galaxies and have the neccessary files, uncomment lines at the end and change dogal to 'y'.\n",
    "\n",
    "RA =    [9.43]\n",
    "DEC =   [1.0]\n",
    "SIM =   [23]\n",
    "IDX =   [0]\n",
    "Z =     [7.2]\n",
    "mag_F158_Av1_6523 = [3.0]\n",
    "unique_ID = [23]\n",
    "\n",
    "gal_input = None\n",
    "\n",
    "dogal='n'\n",
    "\n",
    "# gal_input = Table([RA, DEC, SIM, IDX, Z, mag_F158_Av1_6523, unique_ID],\n",
    "#                   names=(\"RA\",\"DEC\",\"SIM\",\"IDX\",\"Z\",\"mag_F158_Av1.6523\",\"unique_ID\"))\n",
    "\n",
    "# gal_input = Table.read('/global/cfs/cdirs/m4943/grismsim/galacticus_4deg2_mock/Euclid_Roman_4deg2_radec.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68eb47ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the telescope pointing\n",
    "\n",
    "tel_ra = 9.5\n",
    "tel_dec = 1\n",
    "pa = 0\n",
    "det_num = 1\n",
    "\n",
    "# Which directory to save the fits in?\n",
    "\n",
    "outdir = \"\"\n",
    "\n",
    "if len(outdir) == 0:\n",
    "    raise Exception(\"You must specify where to save the fits files.\")\n",
    "\n",
    "# Other arguments typically passed into mk_grism\n",
    "confver='03192025_rotAonly'\n",
    "extra_grism_name=''\n",
    "gal_mag_col='mag_F158_Av1.6523'\n",
    "magmax=25\n",
    "\n",
    "mockdir = \"\"\n",
    "\n",
    "if len(mockdir) == 0:\n",
    "    raise Exception(\"mockdir must point to a directory containing the Galacticus mocks. \\\n",
    "If using NERSC, set mockdir='/global/cfs/cdirs/m4943/grismsim/galacticus_4deg2_mock/'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e05870c",
   "metadata": {},
   "source": [
    "## Prepare fake fits files for Grizli\n",
    "\n",
    "From here on, we're in the realm of grism_sim/py/grism_sim_psf_dependent.py and it's function mk_grism().\n",
    "\n",
    "First, we load grizli_config.yaml. Then, we need to define our WCS. Next, we prepare fake fits files with proper headers. This gives Grizli the information it needs to function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45b37f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read config file and Prepare WCS info\n",
    "\n",
    "conf_file = os.path.join(github_dir, \"grism_sim/data/grizli_config.yaml\")\n",
    "with open(conf_file) as f:\n",
    "    grizli_conf = yaml.safe_load(f)\n",
    "\n",
    "det = \"SCA{:02}\".format(det_num)\n",
    "fov_pixels = grizli_conf[\"fov_pixels\"]\n",
    "gpad = grizli_conf[\"pad\"]\n",
    "tot_im_size = grizli_conf[\"detector_size\"]+2*gpad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7f505d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create WCS\n",
    "\n",
    "code_data_dir = github_dir+'/observing-program/data/'\n",
    "rctrans = ctrans.RomanCoordsTransform(file_path=code_data_dir)\n",
    "dfoot = rctrans.wfi_sky_pointing(tel_ra, tel_dec, pa+60, ds9=False)\n",
    "ra = dfoot[0][int(det_num)]['ra_cen']\n",
    "dec = dfoot[0][int(det_num)]['dec_cen']\n",
    "\n",
    "im_head = iu.fake_header_wcs(ra, dec, crpix2=tot_im_size/2,crpix1=tot_im_size/2,crota2=pa,naxis1=tot_im_size,naxis2=tot_im_size)\n",
    "im_wcs = WCS(im_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554229d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare fits contents: Header info and empty/zero array\n",
    "\n",
    "full_model = np.zeros((tot_im_size, tot_im_size))\n",
    "\n",
    "background = grizli_conf[\"grism_background\"]\n",
    "EXPTIME = 301 \n",
    "NEXP = 1\n",
    "\n",
    "fn_root = 'refimage_ra%s_dec%s_pa%s_det%s' % (tel_ra,tel_dec,pa,det)\n",
    "empty_direct_fits_out_nopad = os.path.join(outdir,fn_root+'_nopad.fits')\n",
    "\n",
    "full_ref = np.zeros((tot_im_size, tot_im_size))\n",
    "full_model = np.zeros((tot_im_size, tot_im_size))\n",
    "phdu = fits.PrimaryHDU(data=full_model)\n",
    "phdu.header[\"INSTRUME\"] = 'ROMAN   '\n",
    "phdu.header[\"FILTER\"] = \"f140w\"\n",
    "phdu.header[\"EXPTIME\"] = 141\n",
    "shp = full_model.shape\n",
    "phdu.header = iu.add_wcs(phdu,ra, dec, crpix2=shp[1]/2,crpix1=shp[0]/2,crota2=pa,naxis1=shp[0],naxis2=shp[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c998717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save fake fits\n",
    "\n",
    "err = np.random.poisson(10,full_model.shape)*0.001 #np.zeros(full_model.shape)\n",
    "ihdu = fits.ImageHDU(data=full_model,name='SCI',header=phdu.header)\n",
    "ehdu = fits.ImageHDU(data=err,name='ERR',header=phdu.header)\n",
    "dhdu = fits.ImageHDU(data=np.zeros(full_model.shape),name='DQ',header=phdu.header)\n",
    "hdul = fits.HDUList([phdu,ihdu,ehdu,dhdu])\n",
    "hdul.writeto(empty_direct_fits_out_nopad, overwrite=True)\n",
    "\n",
    "# Save empty grism fits\n",
    "fn_root_grism = 'grism_ra%s_dec%s_pa%s_det%s' % (tel_ra,tel_dec,pa,det)\n",
    "fn_root_grism += extra_grism_name \n",
    "empty_grism = os.path.join(outdir, 'empty_'+fn_root_grism+'.fits')\n",
    "h, _ = grizli.fake_image.roman_header(ra=ra, dec=dec, pa_aper=pa, naxis=(4088,4088))\n",
    "grizli.fake_image.make_fake_image(h, output=empty_grism, exptime=EXPTIME, nexp=NEXP, background=background)\n",
    "file = fits.open(empty_grism)\n",
    "file[1].header[\"CONFFILE\"] = os.path.join(github_dir, \"grism_sim/data/Roman.det\"+str(det_num)+\".\"+confver+\".conf\") #% (det_num,confver))\n",
    "file.writeto(empty_grism, overwrite=True)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6b06e6",
   "metadata": {},
   "source": [
    "## Prepare object catalogs\n",
    "\n",
    "We need to convert the catalogs from RA & DEC to detector coordinates. Then, we can cut the catalogs to only include objects which are on the detector for our pointing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7436d16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Star RA/DEC -> detector coords\n",
    "star_coords = SkyCoord(ra=star_input['RA']*u.degree,dec=star_input['DEC']*u.degree, frame='icrs')\n",
    "star_xy = im_wcs.world_to_pixel(star_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdc6d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Star cuts\n",
    "sel_ondet = star_xy[0] > 0#stars00['Xpos'] < 4088 + 2*( gpad) #we want everything within padded area around grism\n",
    "sel_ondet &= star_xy[0] < 4088 + 2*( gpad)\n",
    "sel_ondet &= star_xy[1] > 0#stars00['Xpos'] < 4088 + 2*( gpad) #we want everything within padded area around grism\n",
    "sel_ondet &= star_xy[1] < 4088 + 2*( gpad)\n",
    "\n",
    "print('cutting stars to be on detector + padded area')\n",
    "stars = star_input[sel_ondet]\n",
    "stars['Xpos'] = star_xy[0][sel_ondet]\n",
    "stars['Ypos'] = star_xy[1][sel_ondet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e322eee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Galaxy RA/DEC -> detector coords\n",
    "if dogal == 'y':\n",
    "    gal_coords = SkyCoord(ra=(gal_input['RA'])*u.degree,dec=gal_input['DEC']*u.degree, frame='icrs')\n",
    "    gal_xy = im_wcs.world_to_pixel(gal_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bc2330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On-detector galaxy cuts\n",
    "ngal = 0\n",
    "if dogal == 'y':\n",
    "    sel_ondet = gal_xy[0] > 0\n",
    "    sel_ondet &= gal_xy[0] < 4088 + 2*( gpad)\n",
    "    sel_ondet &= gal_xy[1] > 0\n",
    "    sel_ondet &= gal_xy[1] < 4088 + 2*( gpad)\n",
    "    gals = Table(gal_input[sel_ondet])\n",
    "    gals['Xpos'] = gal_xy[0][sel_ondet]\n",
    "    gals['Ypos'] = gal_xy[1][sel_ondet]\n",
    "    gals.rename_column(gal_mag_col, 'mag')\n",
    "    sel_mag = gals['mag'] < magmax\n",
    "    gals = gals[sel_mag]\n",
    "    ngal = len(gals)\n",
    "    print('number of galaxies within detector padded region is '+str(ngal))\n",
    "\n",
    "    #fiducial galaxy profile\n",
    "    \n",
    "    r_eff = 2.5 #radius for profile in pixels\n",
    "    x, y = np.meshgrid(np.arange(-15,15), np.arange(-15,15)) #30x30 grid of pixels\n",
    "    from astropy.modeling.models import Sersic2D\n",
    "    round_exp = Sersic2D(amplitude=1, r_eff=r_eff,n=1) #round exponential \n",
    "    testprof = round_exp(x,y) #np.ones((4,4)) #just something that is not a pointsource, this should get much better\n",
    "    testprof /= np.sum(testprof) #normalize the profile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfac9c25",
   "metadata": {},
   "source": [
    "## Read bandpass file, setup apodization, and instantiate grizli\n",
    "\n",
    "We need to read in one more file, and setup a few more variable which will used within our long for-loop. Finally, we'll instantiate Grizli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289eadda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load bandpass file, read config file info, and define star template indicies\n",
    "df = Table.read(os.path.join(github_dir, 'grism_sim/data/wfirst_wfi_f158_001_syn.fits'), format='fits') #close to H-band\n",
    "bp = S.ArrayBandpass(df[\"WAVELENGTH\"], df[\"THROUGHPUT\"])\n",
    "\n",
    "tempdir = os.path.join(github_dir, 'star_fields/data/SEDtemplates/')\n",
    "templates = open(os.path.join(github_dir, 'star_fields/data/SEDtemplates/input_spectral_STARS.lis')).readlines()\n",
    "temp_inds = stars['star_template_index'] - 58*(stars['star_template_index']//58)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547e9a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup roll-on/roll-off shape\n",
    "spectrum_overlap = grizli_conf[\"spectrum_overlap\"]\n",
    "window_x = np.linspace(0, np.pi, spectrum_overlap)\n",
    "front_y = (1 - np.cos(window_x)) / 2\n",
    "back_y = 1 - front_y\n",
    "\n",
    "# This roll-on/roll-off allows Grizli to smoothly transition from one segment of the dispersion to the next. \n",
    "# Grizli's dispersion relies on FFT. So, without this apodizing, the ends of each dispersion get weird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d06dcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define resolution of the wavelength-dependence of the PSF\n",
    "# more psfs is generally smoother, but the compute-time scales roughly linearly\n",
    "\n",
    "minlam = grizli_conf[\"minlam\"]\n",
    "maxlam = grizli_conf[\"maxlam\"]\n",
    "npsfs = grizli_conf[\"npsfs\"]\n",
    "\n",
    "bins = np.linspace(minlam, maxlam, npsfs + 1)\n",
    "\n",
    "psf_kwargs = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfd0346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the required PSF grids exist\n",
    "\n",
    "for start_wave in bins[:-1]:\n",
    "    \n",
    "    psf_filename = f\"wfi_grism0_fovp364_wave{start_wave:.0f}_{det}.fits\".lower() # {instrument}_{filter}_{fovp}_wave{wavelength}_{det}.fits\n",
    "    print(f\"Checking {psf_filename}\")\n",
    "\n",
    "    try:\n",
    "        psf_grid = pgu.load_psf_grid(psf_filename)\n",
    "\n",
    "    except OSError as e:\n",
    "        print(f\"\\nPSF Grid fits file not found. Check wavelength bins. If needed, use psf_grids to generate new grids. \\n\")\n",
    "        raise e\n",
    "\n",
    "    psf_fp = os.path.join(psf_grid_data_read, psf_filename)\n",
    "    if psf_kwargs is not None:\n",
    "        pgu.check_version(psf_fp, **psf_kwargs)\n",
    "    else:\n",
    "        pgu.check_version(psf_fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070416fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Grizli GrismFLT object\n",
    "size = grizli_conf[\"size\"][det]\n",
    "thresh = 0.01\n",
    "\n",
    "# Instantiate Grizli GrizliFLT\n",
    "roman = GrismFLT(grism_file=empty_grism,ref_file=empty_direct_fits_out_nopad, seg_file=None, pad=gpad) \n",
    "roman.seg = np.zeros((tot_im_size,tot_im_size), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7105759b",
   "metadata": {},
   "source": [
    "## Run the simulation\n",
    "\n",
    "This can be seperated into a few parts: load psf grid, place object on the direct image and segmentation map, call grizli to disperse. These happen in a loop over 20 wavelengths. The second two, placing the object and calling grizli, happen in another loop over every object in the catalogs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b07f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for-loop iterating over wavelength segments\n",
    "    # define spectrum segment limits\n",
    "    # read psf grid\n",
    "    # for-loop iterating over objects (stars & galaxies)\n",
    "        # place object\n",
    "        # Grizli sim\n",
    "        # Save to full_model\n",
    "\n",
    "for ii, start_wave in enumerate(bins[:-1]):\n",
    "    end_wave = bins[ii+1]\n",
    "    print(f\"starting at {start_wave}\")\n",
    "\n",
    "    psf_filename = f\"wfi_grism0_fovp364_wave{start_wave:.0f}_{det}.fits\".lower() # {instrument}_{filter}_{fovp}_wave{wavelength}_{det}.fits\n",
    "    psf_grid = pgu.load_psf_grid(psf_filename)\n",
    "\n",
    "    # STAR SIM\n",
    "    print(\"adding stars to model\")\n",
    "    for i in tqdm(range(0,len(stars))):\n",
    "        photid = i+1\n",
    "\n",
    "        # STAR DIRECT\n",
    "        # direct read of characteristics\n",
    "        xpos = stars[i]['Xpos']\n",
    "        ypos = stars[i]['Ypos']\n",
    "        mag = stars[i]['magnitude']\n",
    "\n",
    "        # cleaned up characteristisc\n",
    "        xp = int(xpos) \n",
    "        yp = int(ypos)\n",
    "        xtrue = xpos - gpad\n",
    "        ytrue = ypos - gpad\n",
    "\n",
    "        sp = iu.star_postage_grid(psf_grid,mag,xtrue,ytrue,fov_pixels=fov_pixels) # PSF from grid\n",
    "\n",
    "        # sp limits are needed to keep only what fits on the detector (plus pad)\n",
    "        sp_lims = [max(0,-(yp-fov_pixels)), min(fov_pixels*2,fov_pixels*2-(yp+fov_pixels-tot_im_size)),\n",
    "                    max(0,-(xp-fov_pixels)), min(fov_pixels*2,fov_pixels*2-(xp+fov_pixels-tot_im_size))]\n",
    "\n",
    "        roman_lims = [max(0, yp-fov_pixels), min(tot_im_size, yp+fov_pixels), \n",
    "                        max(0, xp-fov_pixels), min(tot_im_size, xp+fov_pixels)]\n",
    "\n",
    "        # Set direct image equal to sp; don't add\n",
    "        roman.direct.data[\"REF\"][roman_lims[0]:roman_lims[1], roman_lims[2]:roman_lims[3]] = sp[sp_lims[0]:sp_lims[1],sp_lims[2]:sp_lims[3]]\n",
    "        roman.direct.data['REF'] *= roman.direct.ref_photflam \n",
    "\n",
    "        if start_wave==minlam:\n",
    "            full_ref[roman_lims[0]:roman_lims[1], roman_lims[2]:roman_lims[3]] += sp[sp_lims[0]:sp_lims[1],sp_lims[2]:sp_lims[3]]\n",
    "\n",
    "        # Define selseg from original sp\n",
    "        selseg = sp[sp_lims[0]:sp_lims[1],sp_lims[2]:sp_lims[3]] > thresh\n",
    "        # set seg; use unique ids to make other spaces irrelevant (no need to reset between stars)\n",
    "        roman.seg[roman_lims[0]:roman_lims[1], roman_lims[2]:roman_lims[3]][selseg] = photid \n",
    "\n",
    "        # Rotations after placement on detector\n",
    "        roman.direct.data[\"REF\"] = np.rot90(roman.direct.data[\"REF\"], k=3)\n",
    "        roman.seg = np.rot90(roman.seg, k=3)\n",
    "\n",
    "        # STAR GRISM\n",
    "        row = stars[i]\n",
    "        mag = row[\"magnitude\"]\n",
    "        temp_ind = int(temp_inds[i])\n",
    "        #print(temp_ind)\n",
    "        star_type = templates[temp_ind].strip('\\n')\n",
    "        temp = np.loadtxt(os.path.join(tempdir, star_type)).transpose()\n",
    "        wave = temp[0]\n",
    "        flux = temp[1]\n",
    "\n",
    "        # renormalization has to occur before picking out the spectrum segment to avoid a DisjointError\n",
    "        star_spec = S.ArraySpectrum(wave=wave, flux=flux, waveunits=\"angstroms\", fluxunits=\"flam\")\n",
    "        spec = star_spec.renorm(mag, \"abmag\", bp)\n",
    "        spec.convert(\"flam\")\n",
    "\n",
    "        # if-elses enforce minlam/maxlam bounds on the spectrum (and avoid issues with negative indicies)\n",
    "        if start_wave != minlam:\n",
    "            # Adjust start_wave to include overlap region\n",
    "            start_wave_index = np.searchsorted(spec.wave, start_wave, side=\"left\")\n",
    "            start_index_w_overlap = start_wave_index - int(spectrum_overlap * 0.5)\n",
    "            sel = wave >= spec.wave[start_index_w_overlap]\n",
    "        else:\n",
    "            # Set lower limit on sel_wave\n",
    "            sel = wave >= start_wave\n",
    "\n",
    "        if end_wave != maxlam:\n",
    "            # Adjust end_wave to include overlap region\n",
    "            end_wave_index = np.searchsorted(spec.wave, end_wave, side=\"right\")\n",
    "            end_index_w_overlap = end_wave_index + int(spectrum_overlap * 0.5 - 1) \n",
    "            sel &= wave < spec.wave[end_index_w_overlap]\n",
    "        else:\n",
    "            # Set upper limit on sel_wave\n",
    "            sel &= wave <= end_wave\n",
    "        \n",
    "        # pick out segment of spectrum\n",
    "        wave = spec.wave[sel]\n",
    "        flux = spec.flux[sel]\n",
    "\n",
    "        # apodize/roll-on, roll-off\n",
    "        if start_wave != minlam:\n",
    "            flux[:spectrum_overlap] *= front_y\n",
    "        if end_wave != maxlam:\n",
    "            flux[-spectrum_overlap:] *= back_y            \n",
    "        \n",
    "        segment_of_dispersion = roman.compute_model_orders(id=photid, mag=mag, compute_size=False, size=size, in_place=False, store=False,\n",
    "                                is_cgs=True, spectrum_1d=[wave, flux])\n",
    "        \n",
    "        # compute_model_orders returns a boolean IF the dispersion would not land on the detector\n",
    "        try:\n",
    "            full_model += segment_of_dispersion[1]\n",
    "        except TypeError: # catch \"cannot index bool\" error\n",
    "            continue\n",
    "\n",
    "    if ngal > 0:\n",
    "        print('adding galaxies to model')\n",
    "        for i in tqdm(range(0,ngal)):\n",
    "            if \"photid\" not in locals():\n",
    "                photid = 0\n",
    "            photid += 1\n",
    "            row = gals[i]\n",
    "\n",
    "            # direct read of characteristics\n",
    "            xpos = row['Xpos']\n",
    "            ypos = row['Ypos']\n",
    "            mag = row['mag']\n",
    "\n",
    "            # cleaned up characteristisc\n",
    "            xp = int(xpos) \n",
    "            yp = int(ypos)\n",
    "            xtrue = xpos - gpad\n",
    "            ytrue = ypos - gpad\n",
    "\n",
    "            # make direct thumbnail and convolve with psf\n",
    "            imflux = iu.mag2flux(mag)#imflux = row['flux']\n",
    "            gal_psf = iu.gal_postage_grid(psf_grid,xtrue,ytrue,fov_pixels=fov_pixels)\n",
    "            conv_prof = signal.convolve2d(gal_psf,testprof,mode='same') \n",
    "            sp = imflux*conv_prof\n",
    "\n",
    "            # sp limits are needed to keep only what fits on the detector (plus pad)\n",
    "            sp_lims = [max(0,-(yp-fov_pixels)), min(fov_pixels*2,fov_pixels*2-(yp+fov_pixels-tot_im_size)),\n",
    "                        max(0,-(xp-fov_pixels)), min(fov_pixels*2,fov_pixels*2-(xp+fov_pixels-tot_im_size))]\n",
    "\n",
    "            roman_lims = [max(0, yp-fov_pixels), min(tot_im_size, yp+fov_pixels), \n",
    "                            max(0, xp-fov_pixels), min(tot_im_size, xp+fov_pixels)]\n",
    "\n",
    "            # Set direct image equal to sp; don't add\n",
    "            roman.direct.data[\"REF\"][roman_lims[0]:roman_lims[1], roman_lims[2]:roman_lims[3]] = sp[sp_lims[0]:sp_lims[1],sp_lims[2]:sp_lims[3]]\n",
    "            roman.direct.data['REF'] *= roman.direct.ref_photflam\n",
    "\n",
    "            if start_wave==minlam:\n",
    "                full_ref[roman_lims[0]:roman_lims[1], roman_lims[2]:roman_lims[3]] += sp[sp_lims[0]:sp_lims[1],sp_lims[2]:sp_lims[3]]\n",
    "            \n",
    "            selseg = sp[sp_lims[0]:sp_lims[1],sp_lims[2]:sp_lims[3]] > thresh\n",
    "            roman.seg[roman_lims[0]:roman_lims[1], roman_lims[2]:roman_lims[3]][selseg] = photid\n",
    "\n",
    "            # Rotations after placement on detector\n",
    "            roman.direct.data[\"REF\"] = np.rot90(roman.direct.data[\"REF\"], k=3)\n",
    "            roman.seg = np.rot90(roman.seg, k=3)\n",
    "            \n",
    "            #get sed and convert to spectrum\n",
    "            sim_fn = os.path.join(mockdir, 'galacticus_FOV_EVERY100_sub_'+str(row['SIM'])+'.hdf5')\n",
    "            sim = h5py.File(sim_fn, 'r')\n",
    "            sed_flux = sim['Outputs']['SED:observed:dust:Av1.6523'][row['IDX']]\n",
    "\n",
    "            # initial cut to avoid errors from nan values\n",
    "            wave = np.linspace(2000, 40000, 19001) #wavelength grid for simulation\n",
    "            sel_wave = wave > minlam\n",
    "            sel_wave &= wave < maxlam\n",
    "            wave = wave[sel_wave]\n",
    "            flux = sed_flux[sel_wave]\n",
    "            \n",
    "            gal_spec = S.ArraySpectrum(wave=wave, flux=flux, waveunits=\"angstroms\", fluxunits=\"flam\")\n",
    "            spec = gal_spec.renorm(mag, \"abmag\", bp) # renorm and convert units\n",
    "            spec.convert(\"flam\") \n",
    "\n",
    "            # if-elses enforce minlam/maxlam bounds on the spectrum (and avoid issues with negative indicies)\n",
    "            if start_wave != minlam:\n",
    "                # Adjust start_wave to include overlap region\n",
    "                start_wave_index = np.searchsorted(spec.wave, start_wave, side=\"left\")\n",
    "                start_index_w_overlap = start_wave_index - int(spectrum_overlap * 0.5)\n",
    "                sel_wave = spec.wave >= spec.wave[start_index_w_overlap]\n",
    "            else:\n",
    "                # Set lower limit on sel_wave\n",
    "                sel_wave = spec.wave >= start_wave\n",
    "\n",
    "            if end_wave != maxlam:\n",
    "                # Adjust end_wave to include overlap region\n",
    "                end_wave_index = np.searchsorted(spec.wave, end_wave, side=\"right\")\n",
    "                end_index_w_overlap = end_wave_index + int(spectrum_overlap * 0.5 - 1) \n",
    "                sel_wave &= spec.wave < spec.wave[end_index_w_overlap]\n",
    "            else:\n",
    "                # Set upper limit on sel_wave\n",
    "                sel_wave &= spec.wave <= end_wave\n",
    "\n",
    "            # pick out segment of spectrum\n",
    "            wave = spec.wave[sel_wave]\n",
    "            flux = spec.flux[sel_wave]\n",
    "\n",
    "            # apodize/roll-on, roll-off\n",
    "            if start_wave != minlam:\n",
    "                flux[:spectrum_overlap] *= front_y\n",
    "            if end_wave != maxlam:\n",
    "                flux[-spectrum_overlap:] *= back_y    \n",
    "\n",
    "            segment_of_dispersion = roman.compute_model_orders(id=photid, mag=mag, compute_size=False, size=size, in_place=False, store=False,\n",
    "                                    is_cgs=True, spectrum_1d=[wave, flux])\n",
    "            \n",
    "            # compute_model_orders returns a boolean IF the dispersion would not land on the detector\n",
    "            try:\n",
    "                full_model += segment_of_dispersion[1] # catch \"cannot index bool\" error\n",
    "            except TypeError:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc3fff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final model rotation\n",
    "\n",
    "roman.model = np.rot90(full_model, k=1)\n",
    "\n",
    "# Save model\n",
    "\n",
    "hdu_list = fits.open(empty_grism)\n",
    "if gpad != 0:\n",
    "    hdu_list.append(fits.ImageHDU(data=roman.model[gpad:-gpad, gpad:-gpad],name='MODEL'))\n",
    "    #hdu_list.append(fits.ImageHDU(data=roman.grism.data['SCI'][gpad:-gpad, gpad:-gpad],name='ERR'))\n",
    "    hdu_list['ERR'].data = roman.grism.data['SCI'][gpad:-gpad, gpad:-gpad]\n",
    "else:\n",
    "    hdu_list.append(fits.ImageHDU(data=roman.model,name='MODEL'))\n",
    "    #hdu_list.append(fits.ImageHDU(data=roman.grism.data['SCI']),name='ERR')\n",
    "    hdu_list['ERR'].data = roman.grism.data['SCI']\n",
    "\n",
    "out_fn = os.path.join(outdir, fn_root_grism+'.fits')\n",
    "hdu_list.writeto(out_fn, overwrite=True)\n",
    "hdu_list.close()\n",
    "print('wrote to '+out_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44907984",
   "metadata": {},
   "source": [
    "## Observe the result\n",
    "\n",
    "At this point, the simulation is done. The next few cells are dedicated to reading in the results generated here and showing them in-notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cd996c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams[\"image.interpolation\"] = \"nearest\"\n",
    "mpl.rcParams[\"image.origin\"] = \"lower\"\n",
    "mpl.rcParams[\"figure.figsize\"] = (15,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac41fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = fits.open(out_fn)\n",
    "model_data = model_file[4].data\n",
    "\n",
    "plt.imshow(np.log(model_data+1), cmap=\"hot\", vmin=0, vmax=27)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grizli-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
